parent: [[Обучение простых ML-алгоритмов для классификации]]

tags: #reading #mlbookclub #ml 

Вся идея нейрона Маккалока и Питтса, а также персептрона Розенблата заключается в том, отдельный нейрон, в зависимости от входа либо активируется, либо нет.

Алгоритм персептрона может быть сведен к следующим шагам:

1. Инициализировать веса и смещение нулями или небольшими случайными значениями
2. Для каждого обучающего образца $x^{(i)}$:
	1. Вычислить выходное значение $\hat{y}$ 
	2. Обновить веса и смещение

Здесь выходным значением является метка прогнозируемого класса, а одновременное обновление весов формально может быть записано так:
$$\begin{align}&w_j:=w_j+\Delta w_j\\&b_j:=b_j+\Delta b_j\end{align}$$
Обновляющее значение для $\Delta w_j$ вычисляется следующим образом:

$$\begin{align*}&\Delta w_j=\eta(y^{(i)}-\hat{y}^{(i)})x_j^{(i)}\\&и \\&\Delta b=\eta(y^{(i)}-\hat{y}^{(i)})\end{align*}$$
где 